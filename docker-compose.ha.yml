# This docker-compose file is provided as an example to create a Docker Swarm based MSActivator setup
version: '3.8'
services:
  msa-front:
    image: openmsa/openmsa:msa2-front-2.7.1-6fb886ab36712fcf8f9a4dd6ec520bc50573c0ff
    depends_on:
    - msa-api
    - msa-ui
    - camunda
    - msa-ai-ml
    healthcheck:
      test: [CMD-SHELL, curl -k --fail https://localhost]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
        - node.role==manager
    ports:
    - target: 80
      published: 80
      protocol: tcp
      mode: ingress
    - target: 443
      published: 443
      protocol: tcp
      mode: ingress
    - target: 514
      published: 514
      protocol: udp
      mode: ingress
    - target: 162
      published: 162
      protocol: udp
      mode: ingress
    - target: 69
      published: 69
      protocol: udp
      mode: ingress
    - 5200-5200:5200-5200/udp
    #
    # uncomment one of the 2 sections below when installing a custom certificate 
    # - Docker standard standalone installation
    #volumes:
    #    - "msa_front:/etc/nginx/ssl"
    # - Docker Swarm HA installation
    #volumes:
    #    - "/mnt/NASVolume/msa_front:/etc/nginx/ssl"

  db:
    image: openmsa/openmsa:msa2-db-2.7.1-3fcbdecf6f64fa126deb88db61bcb0ebec3cf92d
    command: postgres -c 'max_connections=800' -c "max_prepared_transactions=100"
    healthcheck:
      test: [CMD-SHELL, pg_isready -U postgres]
      interval: 30s
      timeout: 60s
      retries: 5
    environment:
      POSTGRES_PASSWORD: my_db_password
      POSTGRES_DB: POSTGRESQL
      CAMUNDA_PASSWORD: camunda
      CAMUNDA_DB: process-engine
      CAMUNDA_USER: camunda
    volumes:
    - /mnt/NASVolume/msa_db:/var/lib/postgresql/data
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
  msa-api:
    image: openmsa/openmsa:msa2-api-2.7.1-06a14410d5cc546291a5b9eb0273f534772e5f77
    depends_on:
    - db
    healthcheck:
      test: [CMD-SHELL, curl --fail http://localhost:8480]
    environment:
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
      restart_policy:
        condition: on-failure
        max_attempts: 10
    volumes:
    - /mnt/NASVolume/msa_dev:/opt/devops/
    - /mnt/NASVolume/rrd_repository:/opt/rrd
    - /mnt/NASVolume/msa_entities:/opt/fmc_entities
    - /mnt/NASVolume/msa_repository:/opt/fmc_repository
    - /mnt/NASVolume/msa_api_logs:/opt/wildfly/logs/processLog
    - /mnt/NASVolume/msa_api_keystore:/etc/pki/jentreprise
    networks:
      default:
        aliases:
        - msa_api
  msa-ui:
    image: openmsa/openmsa:msa2-ui-2.7.1-6ffb578e0ef967c0e6ba45802a539750af561e6e
    depends_on:
    - msa-api
    healthcheck:
      test: [CMD-SHELL, curl --fail http://localhost:8080]
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
        - node.role==manager
    environment:
    - FEATURE_ADMIN=true
    - FEATURE_CONNECTION_STATUS=true
    - FEATURE_ALARMS=true
    - FEATURE_LICENCE=true
    - FEATURE_TOPOLOGY=true
    - FEATURE_MONITORING_PROFILES=true
    - FEATURE_SCHEDULE_WORKFLOWS=true
    - FEATURE_PROFILE_AUDIT_LOGS=true
    - FEATURE_PERMISSION_PROFILES=true
    - FEATURE_AI_ML=true
    - FEATURE_WORKFLOW_OWNER=false
    networks:
      default:
        aliases:
        - msa_ui
  msa-sms:
    image: openmsa/openmsa:msa2-sms-2.7.1-4267849ebdda5d65962ef23ad1d97aebb167762a
    depends_on:
    - db
    healthcheck:
      test: [CMD-SHELL, /etc/init.d/ubi-sms status | grep -q 'service seems UP' ||
          exit 1]
    environment:
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    - CONTAINER_DOCKNAME={{.Task.Name}}.{{.Node.Hostname}}
    hostname: '{{.Task.Name}}.{{.Node.Hostname}}'
    volumes:
    - /mnt/NASVolume/msa_dev:/opt/devops/
    - /mnt/NASVolume/msa_entities:/opt/fmc_entities
    - /mnt/NASVolume/msa_repository:/opt/fmc_repository
    - /mnt/NASVolume/rrd_repository:/opt/rrd
    - /mnt/NASVolume/msa_svn:/opt/svnroot
    - /mnt/NASVolume/msa_bulkfiles:/opt/sms/spool/parser
    - /mnt/NASVolume/msa_sms_logs:/opt/sms/logs
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_sms

  msa-bud:
    image: openmsa/openmsa:msa2-bud-2.7.1-ba8a039bf14f40e3873144f0c6827c65ef80516a
    depends_on:
    - db
    healthcheck:
      test: [CMD-SHELL, /etc/init.d/ubi-bud status | grep -q 'service seems UP' ||
          exit 1]
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_bud

  msa-alarm:
    depends_on:
    - db
    - msa-api
    image: openmsa/openmsa:msa2-alarm-2.7.1-3b12f492adb5dd783add52720f0637634f09c551
    healthcheck:
      test: [CMD-SHELL, /etc/init.d/ubi-alarm status | grep -q 'service seems UP'
          || exit 1]
    environment:
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    - CONTAINER_DOCKNAME={{.Task.Name}}.{{.Node.Hostname}}
    hostname: '{{.Task.Name}}.{{.Node.Hostname}}'
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    volumes:
    - /mnt/NASVolume/msa_sms_logs:/opt/sms/logs
    networks:
      default:
        aliases:
        - msa_alarm

  msa-monitoring:
    image: openmsa/openmsa:msa2-monitoring-2.7.1-03c33a60c6c5d6595039aa28e765fd64509d0c29
    healthcheck:
      test: [CMD-SHELL, /etc/init.d/ubi-poll status | grep -q 'service seems UP' ||
          exit 1]
    depends_on:
    - db
    - msa-es
    - msa-dev
    - msa-api
    environment:
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
    - /mnt/NASVolume/msa_dev:/opt/devops/
    - /mnt/NASVolume/msa_entities:/opt/fmc_entities
    - /mnt/NASVolume/msa_repository:/opt/fmc_repository
    - /mnt/NASVolume/rrd_repository:/opt/rrd
    - /mnt/NASVolume/msa_bulkfiles:/opt/sms/spool/parser
    - /mnt/NASVolume/msa_sms_logs:/opt/sms/logs
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_monitoring

  camunda:
    depends_on:
    - db
    image: ubiqube/msa2-camunda:507b2c9b8361821915c4bd9255bafb47ace89079
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    environment:
      DB_DRIVER: org.postgresql.Driver
      DB_URL: jdbc:postgresql://db:5432/process-engine
      DB_USERNAME: camunda
      DB_PASSWORD: camunda
      DB_VALIDATE_ON_BORROW: 'true'
      WAIT_FOR: db:5432
      WAIT_FOR_TIMEOUT: 60
  msa-es:
    image: ubiqube/msa2-es:6b191fca4d76383f04930565d90dbf58a051eed4
    healthcheck:
      test: [CMD-SHELL, "test -f /home/install/init-done && curl -s -XGET -H 'Authorization:\
          \ Basic c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc='  'http://localhost:9200/_cluster/health?pretty'\
          \ | grep -q 'status.*green' || exit 1"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    environment:
    - discovery.type=single-node
    - script.painless.regex.enabled=true
    - bootstrap.memory_lock=true
    - ES_JAVA_OPTS=-Xms512m -Xmx1024m
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
    - /mnt/NASVolume/msa_es:/usr/share/elasticsearch/data
    networks:
      default:
        aliases:
        - msa_es

  msa-kibana:
    image: ubiqube/msa2-kibana:e882bf60f8eeee721e7a9037efd86198ec5a5635
    depends_on:
    - msa-es
    ports:
    - 5601:5601
    environment:
    - ELASTICSEARCH_URL=http://msa_es:9200
    - ELASTICSEARCH_HOSTS=http://msa_es:9200
    - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_kibana
  msa-ai-ml:
    image: ubiqube/msa2-ai-ml:63c7fab8c111b6cc85da049f45ebc6175a9b269a
    healthcheck:
      test: [CMD-SHELL, python /msa_proj/health_check.py]
    ports:
    - 8000:8000
    volumes:
    - /mnt/NASVolume/msa_ai_ml_db:/msa_proj/database
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_ai_ml

  msa-cerebro:
    image: ubiqube/msa2-cerebro:7144f86eec3b2a326066046446187f86a75515b1
    environment:
      AUTH_TYPE: basic
      BASIC_AUTH_USER: cerebro
      BASIC_AUTH_PWD: N@X{M4tfw'5%)+35
    entrypoint:
    - /opt/cerebro/bin/cerebro
    - -Dhosts.0.host=http://msa_es:9200
    depends_on:
    - msa_es
    ports:
    - 9000:9000
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
        - msa_cerebro

  msa-dev:
    image: openmsa/openmsa:msa2-linuxdev-2.7.1-90dd3efa2a57bdaca087d8812a147718a3c4e8ae
    depends_on:
    - msa-es
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    volumes:
    - /mnt/NASVolume/msa_entities:/opt/fmc_entities
    - /mnt/NASVolume/msa_repository:/opt/fmc_repository
    - /mnt/NASVolume/msa_dev:/opt/devops/
    - /mnt/NASVolume/msa_svn:/opt/svnroot
    networks:
      default:
        aliases:
        - msa_dev


networks:
  default:
    driver_opts:
      encrypted: 'true'
