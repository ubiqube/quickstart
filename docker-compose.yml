version: "3.8"

x-es-configuration: &es-configuration
    ES_CREDENTIALS: c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    ES_SERVERS: "msa-es"

x-logging: &logging
  driver: "json-file"
  options:
    mode: non-blocking
    max-buffer-size: "4m"
    max-size: "10m"
    max-file: "5"

x-amqp-syslog: &amqp-syslog
  AMQP_SERVER: "msa-broker"
  AMQP_PORT: "5672"
  AMQP_ADDRESS: "core-engine.syslog"
  AMQP_USER: "artemis"
  AMQP_PASSWORD: "simetraehcapa"

services:
  msa-auth:
    image: ubiqube/msa2-auth:43c88efcb225fd1ba5dec33b466e2ea180d016c6
    environment: 
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: ubiqube
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: timeout 10s bash -c ':> /dev/tcp/127.0.0.1/8080'
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 1m

  msa-front:
    restart: unless-stopped
    container_name: msa_front
    image: ubiqube/msa2-front:f8b7e359e30865d2cc3232adfd2b3a773522870b
    healthcheck:
      test: ["CMD-SHELL", "curl -k --fail https://localhost"]
    depends_on:
      msa-ui:
        condition: service_healthy
      msa-api:
        condition: service_started
      msa-es:
        condition: service_started
      camunda:
        condition: service_started
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
        - "msa_front_conf:/etc/nginx/custom_conf.d"
    networks:
      default:
        aliases:
          - "msa_front"   #
    # uncomment one of the 2 sections below when installing a custom certificate
    # - Docker standard standalone installation
    #volumes:
    #    - "msa_front:/etc/nginx/ssl"
    # - Docker Swarm HA installation
    #volumes:
    #    - "/mnt/NASVolume/msa_front:/etc/nginx/ssl" 

  db:
    restart: unless-stopped
    container_name: msa_db
    image: ubiqube/msa2-db:72042805ec62153025202ff1000f649f5fee59fe
    healthcheck:
      test: ["CMD-SHELL", "/usr/pgsql-12/bin/pg_isready -h localhost"]
      timeout: 20s
      interval: 30s
      retries: 5
    environment:
      CAMUNDA_PASSWORD: camunda
      CAMUNDA_DB: process-engine
      CAMUNDA_USER: camunda
      KEY_VAULT_USER: key_vault
      KEY_VAULT_DB: key_vault
      PG_MODE: primary
      PG_PRIMARY_USER: postgres
      PG_PRIMARY_PASSWORD: my_db_password
      PG_USER: postgres
      PG_PASSWORD: my_db_password
      PG_DATABASE: POSTGRESQL
      PG_ROOT_PASSWORD: my_db_password
      PG_PRIMARY_PORT: 5432
      MAX_CONNECTIONS: 1600
    shm_size: 1g
    logging:
      <<: *logging
    volumes:
      - "msa_db:/pgsqldata/pgsql"

  msa-mongodb:
    image: mongo:7.0
    restart: unless-stopped
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh mongodb://${DB_USER:-msaUser}:${DB_PASSWORD:-ubiqube38}@localhost:${DB_PORT:-27017}/${DB_NAME:-msa} --quiet
    #      ccla must match user created in mongo-init.js
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD:-my_db_password}
    ports:
        - "27017:27017"
    volumes:
        - msa_mongodb_data:/data/db
        - ./mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro

  msa-api:
    restart: unless-stopped
    container_name: msa_api
    image: ubiqube/msa2-api:643b022d04b07f6e74e78524807f01f9b76cd369
    healthcheck:
      test: ["CMD-SHELL", "curl -s --fail http://localhost:8480/actuator/health | grep -q UP"]
      retries: 3
      timeout: 5s
      interval: 10s
      start_period: 90s
    depends_on:
      db:
        condition: service_healthy
      msa-mongodb:
        condition: service_healthy
      msa-es:
        condition: service_started
    environment:
      <<: *es-configuration
      UBIQUBE_CAPTCHA_SECRET_KEY: 6Ld2zF4dAAAAABWD9Q6QAhBql_CIynUeVKaTiBgT
      MANAGEMENT_TRACING_ENABLED: 'true'
    logging:
      <<: *logging
    volumes:
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "rrd_repository:/opt/rrd"
      - "msa_dev:/opt/devops/"
      - "msa_api_logs:/opt/wildfly/logs/"
      - "msa_api_logs:/opt/wildfly/logs/processLog"
      - "msa_api_keystore:/etc/pki/jentreprise"
    networks:
      default:
        aliases:
          - "msa_api"

  msa-ui:
    restart: unless-stopped
    container_name: msa_ui
    image: ubiqube/msa2-ui:8dbb122d4a40b9c2b64db5d06b536b201af7e093
    #image: ubiqube/msa2-ui:test
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080"]
    depends_on:
      msa-api:
        condition: service_started
    environment:
    - FEATURE_ADMIN=true
    - FEATURE_REPOSITORY=true
    - FEATURE_CONNECTION_STATUS=true
    - FEATURE_ALARMS=true
    - FEATURE_LICENCE=true
    - FEATURE_TOPOLOGY=true
    - FEATURE_MONITORING_PROFILES=true
    - FEATURE_PROFILE_AUDIT_LOGS=true
    - FEATURE_PERMISSION_PROFILES=true
    - FEATURE_AI_ML=false
    - FEATURE_MICROSERVICE_BULK_OPERATION=false
    - FEATURE_EDIT_VARIABLES_IN_MICROSERVICE_CONSOLE=true
    - FEATURE_WORKFLOW_OWNER=false
    - FEATURE_PERMISSION_PROFILE_LABELS=false
    - FEATURE_BPM=true
    - UBIQUBE_ES_SECURITY_DISABLED=true
    - FEATURE_ALARMS_AUTO_CLEARANCE=true
    - FEATURE_IMPORT_WITH_SAME_AND_UPPERRANK=true
    - FEATURE_REPOFOLDERLIST=[\"Datafiles\"]
    logging:
      <<: *logging
    networks:
      default:
        aliases:
          - "msa_ui"

  msa-sms:
    restart: unless-stopped
    container_name: msa_sms
    image: ubiqube/msa2-sms:14d129d1cb6812b05985529c6ead389943361961
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    environment:
      <<: *es-configuration
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
    ports:
      - target: 69
        published: 69
        protocol: udp
        mode: host
      - target: 5200
        published: 5200
        protocol: udp
        mode: host
    logging:
      <<: *logging
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "msa_sms_logs:/opt/sms/logs"
      - "msa_svn:/opt/svnroot"
      - "msa_svn_ws:/opt/sms/spool/routerconfigs"
      - "msa_bulkfiles:/opt/sms/spool/parser"
      - "msa_bulkfiles_err:/opt/sms/spool/parser-error"
    networks:
      default:
        aliases:
          - "msa_sms"

  msa-parse:
    restart: unless-stopped
    container_name: msa_parse
    image: ubiqube/msa2-parse:100412daae7431d0930aca976158bc17e097b87d
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
      msa-sms:
        condition: service_healthy
      msa-broker:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    environment:
      <<: [*es-configuration, *amqp-syslog]
    logging:
      <<: *logging
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_parsebulkfiles:/opt/sms/spool/parser"
      - "msa_parsebulkfiles_err:/opt/sms/spool/parser-error"
    networks:
      default:
        aliases:
          - "msa_parse"

  msa-snmptrap:
    restart: unless-stopped
    container_name: msa_snmptrap
    image: ubiqube/msa2-snmptrap:8e61913b77d0391f50f0e03db8297534e135c56f
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    environment:
      <<: *es-configuration
    ports:
      - target: 162
        published: 162
        protocol: udp
        mode: host
    logging:
      <<: *logging
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_repository:/opt/fmc_repository"
      - "msa_snmptrapbulkfiles:/opt/sms/spool/parser"
      - "msa_snmptrapbulkfiles_err:/opt/sms/spool/parser-error"
    networks:
      default:
        aliases:
          - "msa_snmptrap"

  msa-bud:
    restart: unless-stopped
    container_name: msa_bud
    image: ubiqube/msa2-bud:3fe82ad9d9afe09f0aa33540fe914e6b23a7d8b8
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    depends_on:
      db:
        condition: service_healthy
    logging:
      <<: *logging
    volumes:
      - "msa_bud_logs:/opt/bud/logs/"
    networks:
      default:
        aliases:
          - "msa_bud"

  msa-alarm:
    restart: unless-stopped
    container_name: msa_alarm
    image: ubiqube/msa2-alarm:357433368fa6d3a0b2a65b337aca97b1689bb7d9
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-api:
        condition: service_healthy
    environment:
      <<: *es-configuration
    logging:
      <<: *logging
    volumes:
      - "msa_sms_logs:/opt/sms/logs"
      - "msa_alarmbulkfiles:/opt/sms/spool/alarms"
      - "msa_alarmbulkfiles_err:/opt/sms/spool/alarms-error"
    networks:
      default:
        aliases:
          - "msa_alarm"

  msa-monitoring:
    restart: unless-stopped
    container_name: msa_monitoring
    image: ubiqube/msa2-monitoring:917e4e6156d78335644c6612d15e92dfc57f9752
    healthcheck:
      test: ["CMD-SHELL", "/opt/sms/bin/sms -e ISALIVE -t 1 | grep -q OK || exit 1"]
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
      msa-sms:
        condition: service_started
    environment:
      # ES_MON
      # "yes" : ES + RRD
      # "only" : ES only (no RRD)
      # any other values ("no" is recommended!) RRD only (no ES)
      ES_MON: "no"
      <<: *es-configuration
    logging:
      <<: *logging
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "rrd_repository:/opt/rrd"
      - "msa_sms_logs:/opt/sms/logs"
      - "msa_monitbulkfiles:/opt/sms/spool/parser"
      - "msa_monitbulkfiles_err:/opt/sms/spool/parser-error"
    networks:
      default:
        aliases:
          - "msa_monitoring"

  msa-rsyslog:
    restart: unless-stopped
    container_name: msa_rsyslog
    depends_on:
      - msa-parse
    image: ubiqube/msa2-rsyslog:43500ad9def533042983caa4fab55ff2efd1b896
    environment:
      # ACTIONTYPE: omudpspoof or omkafka
      # configure a specific port for TLS. Default is 6514
      # TLS_SYSLOG_PORT: 6514
      ACTIONTYPE: "omamqp1"
      <<: *amqp-syslog
    ports:
      - target: 514
        published: 514
        protocol: udp
        mode: host
      - target: 514
        published: 514
        protocol: tcp
        mode: host
      - target: 6514
        published: 6514
        protocol: tcp
        mode: host
    networks:
      default:
        aliases:
          - "msa_rsyslog"
    logging:
      <<: *logging

  msa-broker:
    restart: unless-stopped
    container_name: msa_broker
    image: docker.io/ubiqube/msa2-broker:bafeae07df27c0c2e0d381890b7a4743cbd961bd
    depends_on:
      - db
    environment:
      ARTEMIS_PASSWORD: simetraehcapa
      ARTEMIS_USER: artemis
      EXTRA_ARGS: --http-host 0.0.0.0 --relax-jolokia --clustered --addresses core-engine.syslog:anycast --queues core-engine.syslog:anycast
    logging:
      <<: *logging
    volumes:
      - "msa_broker:/var/lib/artemis-instance"

  camunda:
    restart: unless-stopped
    container_name: msa_camunda
    depends_on:
      db:
        condition: service_healthy
    image: ubiqube/msa2-camunda:1b1ce13b8a4266f8b0a76164ec68917025bfd062
    environment:
      DB_DRIVER: org.postgresql.Driver
      DB_URL: 'jdbc:postgresql://db:5432/process-engine'
      DB_USERNAME: camunda
      DB_PASSWORD: camunda
      DB_VALIDATION_QUERY: 'SELECT 1'
      DB_VALIDATE_ON_BORROW: 'true'
      WAIT_FOR: 'db:5432'
      WAIT_FOR_TIMEOUT: 60
      MANAGEMENT_TRACING_ENABLED: 'true'
    logging:
      <<: *logging

  msa-es:
    restart: unless-stopped
    container_name: msa_es
    image: ubiqube/msa2-es:5fc4552ecb6c5c28ceb7ce9e3e49b2f7d8816482
    healthcheck:
      test: ["CMD-SHELL", "test -f /home/install/init-done && curl -s -XGET -H 'Authorization: Basic c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc='  'http://localhost:9200/_cluster/health?pretty' | grep -q 'status.*green' || exit 1"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s
    environment:
      discovery.type: "single-node"
      script.painless.regex.enabled: "true"
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms512m -Xmx1024m"
      <<: *es-configuration
    logging:
      <<: *logging
    volumes:
      - "msa_es:/usr/share/elasticsearch/data"
      - "msa_es_config:/usr/share/elasticsearch/config"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9300:9300"
      - "9200:9200"
      - "9300:9300/udp"
      - "9200:9200/udp"
    networks:
      default:
        aliases:
          - "msa_es"

  msa-cerebro:
    restart: unless-stopped
    container_name: msa_cerebro
    image: ubiqube/msa2-cerebro:bf816107bdb08afee0998117c5e90cc660683e6d
    environment:
      AUTH_TYPE: basic
      BASIC_AUTH_USER: cerebro
      BASIC_AUTH_PWD: "N@X{M4tfw'5%)+35"
    entrypoint:
      - /opt/cerebro/bin/cerebro
      - -Dhosts.0.host=http://msa_es:9200
    depends_on:
      msa-es:
        condition: service_started
    logging:
      <<: *logging
    ports:
    - "9000:9000"
    networks:
      default:
        aliases:
          - "msa_cerebro"

  msa-kibana:
    restart: unless-stopped
    container_name: msa_kibana
    image: ubiqube/msa2-kibana:e0567b106dae2b34839ae7dd5dcb436eb67beb98
    depends_on:
      msa-es:
        condition: service_started
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: "http://msa_es:9200"
      ELASTICSEARCH_HOSTS: "http://msa_es:9200"
      <<: *es-configuration
    logging:
      <<: *logging
    networks:
      default:
        aliases:
          - "msa_kibana"

  msa-dev:
    restart: unless-stopped
    container_name: msa_dev
    #build: ./lab/msa_dev
    image: ubiqube/msa2-linuxdev:63c0c3497005d6c046c9b174158c61775a1f2f18
    volumes:
      - "/sys/fs/cgroup:/sys/fs/cgroup:ro"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "msa_dev:/opt/devops/"
      - "msa_front_conf:/etc/nginx/custom_conf.d"
    networks:
      default:
        aliases:
          - "msa_dev"
    logging:
      <<: *logging

  msa-smtp:
    image: boky/postfix:4.2.1-alpine
    environment:
      HOSTNAME: msa-smtp
#      RELAYHOST: <MTA ip>:25
      POSTFIX_message_size_limit: 2097152
      ALLOW_EMPTY_SENDER_DOMAINS: "true"
      ALLOWED_SENDER_DOMAINS: ''

  linux-me:
    restart: unless-stopped
    container_name: linux_me
    # use local image for quickstart dev => for release: make sure the changes are ported to msa-docker and uncomment the line below
    #image: ubiqube/msa2-linuxme:cc4357bc05c6502c7d2ceb7d3c6b090e24a8411e
    image: ubiqube/msa2-linuxme:dfba9fb377cbaec352d7f8eebff57b9b6c2e1b4e
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - DAC_READ_SEARCH
      - sys_rawio
    ports:
      - "2224:22"
    devices:                     # required for dmidecode used by polld/asset
      - "/dev/mem:/dev/mem"
    hostname: linux-me
    privileged: true
    networks:
      default:
        aliases:
          - "linux_me"
        ipv4_address: 172.20.0.101
    logging:
      <<: *logging

  linux-me-2:
    restart: unless-stopped
    container_name: linux_me_2
    # use local image for quickstart dev => for release: make sure the changes are ported to msa-docker and uncomment the line below
    image: ubiqube/msa2-linuxme:dfba9fb377cbaec352d7f8eebff57b9b6c2e1b4e
    build: ./lab/linux.me
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - DAC_READ_SEARCH
      - sys_rawio
    ports:
      - "2225:22"
    devices:                     # required for dmidecode used by polld/asset
      - "/dev/mem:/dev/mem"
    hostname: linux-me-2
    privileged: true
    networks:
      default:
        aliases:
          - "linux_me_2"
        ipv4_address: 172.20.0.102
    logging:
      <<: *logging


  msa2-es-ilm:
    image: ubiqube/msa2-es-ilm:dda9094825d80174afde4d18a9fafcadedb1f7d1
    container_name: msa2_es-ilm
    tty: true
    init: true
    restart: unless-stopped
    networks:
      default:
        aliases:
          - "msa2_es-ilm"
    #healthcheck:
    #  test: ["CMD-SHELL", "find /opt/msa2-es-ilm/log/log_retention.log -type f -mmin -10"]
    depends_on:
      msa-es:
        condition: service_started
    environment:
      ELASTICSEARCH_URL: "msa_es:9200"
      #For elasticsearch scripts /opt/ubi-es-ilm/log_retention_management.php
      #UBI_ES_INDEX_MULTIPLE_TTL:        "type:traffic|7d,type:event|30d,*|90d"
      UBI_ES_INDEX_MULTIPLE_TTL:         "*|90d"
      UBI_ES_AUDIT_INDEX_MULTIPLE_TTL:   "*|90d"
      UBI_ES_LOG_SEARCH_INDEX_LIST:      "ubilogs"
      UBI_ES_RETENTION_INDEX_NAME:       "ubilogs*"
      UBI_ES_RETENTION_AUDIT_INDEX_NAME: "ubiaudit*"
      UBI_ES_RETENTION_ALARM_INDEX_NAME: "ubialarm*"
      UBI_ES_ALARM_INDEX_MULTIPLE_TTL:   "*|90d"
      UBI_ES_CACHE_INDEX_DEFAULT_TTL:    "1w"
      UBI_ES_DELETE_SCROLL_SIZE:         "4000"
      UBI_ES_MAX_DOCS:                   ""
      UBI_ES_LOG_DETENTION_DELETE:       "true"
      UBI_ES_ILM_LOG_CRONTAB:            "# */2 * * * *  php /opt/ubi-es-ilm/log_retention_management.php --verbose=3 > /proc/1/fd/1 2>&1"
      <<: *es-configuration
    volumes:
      - "msa2_es-ilm:/opt/msa2-es-ilm"

  msa-zipkin:
    image: docker.io/openzipkin/zipkin
    environment:
      STORAGE_TYPE: mem
    #  STORAGE_TYPE: elasticsearch
      ES_HOSTS: http://msa-es:9200
      ES_USERNAME: superuser
      ES_PASSWORD: x^ZyuGM6~u=+fY2G
    ports:
      - target: 9411
        published: 9411
        protocol: tcp
        mode: ingress

volumes:
  msa_broker:
  msa_db:
  msa_mongodb_data:
  msa_dev:
  msa_entities:
  msa_repository:
  msa_es:
  msa_es_config:
  rrd_repository:
  msa_api_logs:
  msa_api_keystore:
  msa_sms_logs:
  msa_bud_logs:
  msa_front:
  msa_front_conf:
  msa_svn:
  msa_svn_ws:
  msa_ai_ml_db:
  rsyslog_conf:
  msa_bulkfiles:
  msa_bulkfiles_err:
  msa_parsebulkfiles:
  msa_parsebulkfiles_err:
  msa_snmptrapbulkfiles:
  msa_snmptrapbulkfiles_err:
  msa_monitbulkfiles:
  msa_monitbulkfiles_err:
  msa_alarmbulkfiles:
  msa_alarmbulkfiles_err:
  msa2_es-ilm:

networks:
  default:
    name: quickstart_default
    ipam:
      config:
        - subnet: 172.20.0.0/24
    driver_opts:
      encrypted: "true"
