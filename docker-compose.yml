version: "3.8"

services:
  msa-front:
    restart: unless-stopped
    container_name: msa_front
    image: ubiqube/msa2-front:3791b10ce411b0a5cdd71b6bb7bc82afa93b4f5d
    healthcheck:
      test: ["CMD-SHELL", "curl -k --fail https://localhost"]
    depends_on:
      msa-ui:
        condition: service_healthy
      msa-api:
        condition: service_started
      msa-es:
        condition: service_started
      camunda:
        condition: service_started
      msa-ai-ml:
        condition: service_started
      msa-rsyslog:
        condition: service_started
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: host
      - target: 443
        published: 443
        protocol: tcp
        mode: host
      - target: 162
        published: 162
        protocol: udp
        mode: host
      - target: 69
        published: 69
        protocol: udp
        mode: host
      - "5200-5200:5200-5200/udp"
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
        - "msa_front_conf:/etc/nginx/custom_conf.d"
    networks:
      default:
        aliases:
          - "msa_front"   #
    # uncomment one of the 2 sections below when installing a custom certificate 
    # - Docker standard standalone installation
    #volumes:
    #    - "msa_front:/etc/nginx/ssl"
    # - Docker Swarm HA installation
    #volumes:
    #    - "/mnt/NASVolume/msa_front:/etc/nginx/ssl"

  db:
    restart: unless-stopped
    container_name: msa_db
    image: openmsa/openmsa:msa2-db-2.8.3-f9642e13d1d52b7e3b8480c47ae7a91369e9c959
    healthcheck:
      test: ["CMD-SHELL", "/usr/pgsql-12/bin/pg_isready -h localhost"]
      timeout: 20s
      interval: 30s
      retries: 5
    environment:
      CAMUNDA_PASSWORD: camunda
      CAMUNDA_DB: process-engine
      CAMUNDA_USER: camunda
      KEY_VAULT_USER: key_vault
      KEY_VAULT_DB: key_vault
      PG_MODE: primary
      PG_PRIMARY_USER: postgres
      PG_PRIMARY_PASSWORD: my_db_password
      PG_USER: postgres
      PG_PASSWORD: my_db_password
      PG_DATABASE: POSTGRESQL
      PG_ROOT_PASSWORD: my_db_password
      PG_PRIMARY_PORT: 5432
      MAX_CONNECTIONS: 1600
    shm_size: 1g
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_db:/pgsqldata/pgsql"

  msa-api:
    restart: unless-stopped
    container_name: msa_api
    image: openmsa/openmsa:msa2-api-2.8.3-759a7511420f5b3ad4ba7f5c357622984af8db3d
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8480"]
      retries: 10
      interval: 10s
      start_period: 5s    
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
    environment:
      - "ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc="
      - UBIQUBE_CAPTCHA_SECRET_KEY=6Ld2zF4dAAAAABWD9Q6QAhBql_CIynUeVKaTiBgT
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_api:/opt/ubi-jentreprise/generated/conf"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "rrd_repository:/opt/rrd"
      - "msa_dev:/opt/devops/"
      - "msa_api_logs:/opt/wildfly/logs/"
      - "msa_api_logs:/opt/wildfly/logs/processLog"
      - "msa_api_keystore:/etc/pki/jentreprise"
    networks:
      default:
        aliases:
          - "msa_api"

  msa-ui:
    restart: unless-stopped
    container_name: msa_ui
    image: ubiqube/msa2-ui:0db3c5d685b634daca196849190b8b94562ce87e
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080"]
    depends_on:
      msa-api:
        condition: service_started
    environment:
    - FEATURE_ADMIN=true
    - FEATURE_REPOSITORY=true
    - FEATURE_CONNECTION_STATUS=true
    - FEATURE_ALARMS=true
    - FEATURE_LICENCE=true
    - FEATURE_TOPOLOGY=true
    - FEATURE_MONITORING_PROFILES=true
    - FEATURE_PROFILE_AUDIT_LOGS=true
    - FEATURE_PERMISSION_PROFILES=true
    - FEATURE_AI_ML=false
    - FEATURE_MICROSERVICE_BULK_OPERATION=false
    - FEATURE_EDIT_VARIABLES_IN_MICROSERVICE_CONSOLE=true
    - FEATURE_WORKFLOW_OWNER=false
    - FEATURE_PERMISSION_PROFILE_LABELS=false
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    networks:
      default:
        aliases:
          - "msa_ui"

  msa-sms:
    restart: unless-stopped
    container_name: msa_sms
    image: openmsa/openmsa:msa2-sms-2.8.3-44f77e35c9033946f9c904174ef453b98af2ac39
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s      
      test: ["CMD-SHELL", "/etc/init.d/ubi-sms status | grep -q 'service seems UP' || exit 1"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    cap_add:
      - NET_ADMIN
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "msa_sms_logs:/opt/sms/logs"
      - "msa_svn:/opt/svnroot"
      - "msa_bulkfiles:/opt/sms/spool/parser"
    networks:
      default:
        aliases:
          - "msa_sms"

  msa-bud:
    restart: unless-stopped
    container_name: msa_bud
    image: openmsa/openmsa:msa2-bud-2.8.3-0b9f458ef2d78963c936b61a1ee9ae3299a341bc
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s
      test: ["CMD-SHELL", "/etc/init.d/ubi-bud status | grep -q 'service seems UP' || exit 1"]
    depends_on:
      db:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_bud_logs:/opt/bud/logs/"
    networks:
      default:
        aliases:
          - "msa_bud"

  msa-alarm:
    restart: unless-stopped
    container_name: msa_alarm
    image: openmsa/openmsa:msa2-alarm-2.8.3-c1b98b96a7b32c3cfc88f7fcb7304460dfc84ff4
    healthcheck:
      timeout: 5s
      retries: 10
      interval: 10s
      start_period: 30s
      test: ["CMD-SHELL", "/etc/init.d/ubi-alarm status | grep -q 'service seems UP' || exit 1"]
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
    environment:
      - "ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc="
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_sms_logs:/opt/sms/logs"
    networks:
      default:
        aliases:
          - "msa_alarm"
  
  msa-monitoring:
    restart: unless-stopped
    container_name: msa_monitoring
    image: openmsa/openmsa:msa2-monitoring-2.8.3-0d82be7f6ed084ec80443bcc41a51909766f9ae5
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-poll status | grep -q 'service seems UP' || exit 1"]
    depends_on:
      db:
        condition: service_healthy
      msa-es:
        condition: service_started
      msa-dev:
        condition: service_started
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    volumes:
      - "msa_dev:/opt/devops/"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "rrd_repository:/opt/rrd"
      - "msa_bulkfiles:/opt/sms/spool/parser"
      - "msa_sms_logs:/opt/sms/logs"
    networks:
      default:
        aliases:
          - "msa_monitoring"

  msa-rsyslog:
    restart: unless-stopped
    container_name: msa_rsyslog
    depends_on:
      - msa-sms
    image: openmsa/openmsa:msa2-rsyslog-2.8.3-54a250d9ef49db2454c5ed9111d43cebc8e9ef9a
    ports:
      - target: 514
        published: 514
        protocol: udp
        mode: host
      - target: 514
        published: 514
        protocol: tcp
        mode: host
    networks:
      default:
        aliases:
          - "msa_rsyslog"

  camunda:
    restart: unless-stopped
    container_name: msa_camunda
    depends_on:
      db:
        condition: service_healthy
    image: openmsa/openmsa:msa2-camunda-2.8.0-507b2c9b8361821915c4bd9255bafb47ace89079
    environment:
      DB_DRIVER: org.postgresql.Driver
      DB_URL: 'jdbc:postgresql://db:5432/process-engine'
      DB_USERNAME: camunda
      DB_PASSWORD: camunda
      DB_VALIDATE_ON_BORROW: 'true'
      WAIT_FOR: 'db:5432'
      WAIT_FOR_TIMEOUT: 60
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"

  msa-es:
    restart: unless-stopped
    container_name: msa_es
    image: openmsa/openmsa:msa2-es-2.8.3-f42f585457a4461f06ef1c696fa46bb9f02a187a
    healthcheck:
      test: ["CMD-SHELL", "test -f /home/install/init-done && curl -s -XGET -H 'Authorization: Basic c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc='  'http://localhost:9200/_cluster/health?pretty' | grep -q 'status.*green' || exit 1"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s 
    environment:
      - discovery.type=single-node
      - script.painless.regex.enabled=true
      - bootstrap.memory_lock=true
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx1024m"
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    ports:
      - target: 9200
        published: 9200
        protocol: tcp
        mode: host
      - target: 9300
        published: 9300
        protocol: tcp
        mode: host
    volumes:
      - "msa_es:/usr/share/elasticsearch/data"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      default:
        aliases:
          - "msa_es"

  msa-cerebro:
    restart: unless-stopped
    container_name: msa_cerebro
    image: openmsa/openmsa:msa2-cerebro-2.8.0-914750e000db1343d9972bfa6652da1efe4aa32f
    environment:
      AUTH_TYPE: basic
      BASIC_AUTH_USER: cerebro
      BASIC_AUTH_PWD: "N@X{M4tfw'5%)+35"
    entrypoint:
      - /opt/cerebro/bin/cerebro
      - -Dhosts.0.host=http://msa_es:9200
    depends_on:
      msa-es:
        condition: service_started
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    ports:
    - "9000:9000"
    networks:
      default:
        aliases:
          - "msa_cerebro"
  
  msa-kibana:
    restart: unless-stopped
    container_name: msa_kibana
    image: openmsa/openmsa:msa2-kibana-2.8.3-49c1c422ad5559815d4f74568904a7214e788932
    depends_on:
      msa-es:
        condition: service_started
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_URL=http://msa_es:9200
      - ELASTICSEARCH_HOSTS=http://msa_es:9200
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    logging:
      driver: "json-file"
      options:
        mode: non-blocking
        max-buffer-size: "4m"
        max-size: "10m"
        max-file: "5"
    networks:
      default:
        aliases:
          - "msa_kibana"
          
  msa-ai-ml:
    restart: unless-stopped
    container_name: msa_ai_ml
    image: openmsa/openmsa:msa2-ai-ml-2.8.0-63c7fab8c111b6cc85da049f45ebc6175a9b269a
    healthcheck:
      test: ["CMD-SHELL", "python /msa_proj/health_check.py"]
    ports:
      - "8000:8000"
    volumes:
      - "msa_ai_ml_db:/msa_proj/database"
    networks:
      default:
        aliases:
          - "msa_ai_ml"

  msa-dev:
    restart: unless-stopped
    container_name: msa_dev
    #build: ./lab/msa_dev
    image: openmsa/openmsa:msa2-linuxdev-2.8.3-baec532c6cbde2aa588225020738b1b2f06cc840
    volumes:
      - "/sys/fs/cgroup:/sys/fs/cgroup:ro"
      - "msa_entities:/opt/fmc_entities"
      - "msa_repository:/opt/fmc_repository"
      - "msa_dev:/opt/devops/"
    networks:
      default:
        aliases:
          - "msa_dev"

  linux-me:
    restart: unless-stopped
    container_name: linux_me
    # use local image for quickstart dev => for release: make sure the changes are ported to msa-docker and uncomment the line below
    image: openmsa/openmsa:msa2-linuxme-2.8.0-b831acacdef579420ee1abf70ef66655d969fcbb
    #build: ./lab/linux.me
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - DAC_READ_SEARCH
      - sys_rawio
    ports:
      - "2224:22"
    devices:                     # required for dmidecode used by polld/asset
      - "/dev/mem:/dev/mem"
    hostname: linux-me
    privileged: true
    networks:
      default:
        aliases:
          - "linux_me"
        ipv4_address: 172.20.0.101

  linux-me-2:
    restart: unless-stopped
    container_name: linux_me_2
    # use local image for quickstart dev => for release: make sure the changes are ported to msa-docker and uncomment the line below
    image: openmsa/openmsa:msa2-linuxme-2.8.0-b831acacdef579420ee1abf70ef66655d969fcbb
    #build: ./lab/linux.me
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - DAC_READ_SEARCH
      - sys_rawio
    ports:
      - "2225:22"
    devices:                     # required for dmidecode used by polld/asset
      - "/dev/mem:/dev/mem"
    hostname: linux-me-2
    privileged: true
    networks:
      default:
        aliases:
          - "linux_me_2"
        ipv4_address: 172.20.0.102

volumes:
  msa_api:
  msa_db:
  msa_dev:
  msa_entities:
  msa_repository:
  msa_es:
  rrd_repository:
  msa_api_logs:
  msa_api_keystore:
  msa_sms_logs:
  msa_bud_logs:
  msa_front:
  msa_front_conf:
  msa_svn:
  msa_ai_ml_db:
  msa_bulkfiles:


networks:
  default:
    name: quickstart_default
    ipam:
      config:
        - subnet: 172.20.0.0/24
    driver_opts:
      encrypted: "true"
