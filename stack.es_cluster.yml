# This docker-compose file is provided as an example to create a Docker Swarm based MSActivator setup
version: "3.8"

services:
  msa_front:
    image: openmsa/openmsa:msa2-front-2.8.5-4b91a184d6e114b726b4f1219bd8e05bd8714cc0
    depends_on:
      - msa_api
      - msa_ui
      - camunda
      - msa_ai_ml
    healthcheck:
      test: ["CMD-SHELL", "curl -k --fail https://localhost"] 
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s 
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.role==manager"
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: ingress
      - target: 443
        published: 443
        protocol: tcp
        mode: ingress
      - target: 514
        published: 514
        protocol: udp
        mode: ingress
      - target: 162
        published: 162
        protocol: udp
        mode: ingress
      - target: 69
        published: 69
        protocol: udp
        mode: ingress
      - "5200-5200:5200-5200/udp"
    #
    # uncomment one of the 2 sections below when installing a custom certificate 
    # - Docker standard standalone installation
    #volumes:
    #    - "msa_front:/etc/nginx/ssl"
    # - Docker Swarm HA installation
    #volumes:
    #    - "/mnt/NASVolume/msa_front:/etc/nginx/ssl"

  db:
    restart: unless-stopped
    container_name: msa_db
    image: openmsa/openmsa:msa2-db-2.8.5-c880962c3b96ca67ac457ca34c4b5363fcba0c32
    healthcheck:
      test: ["CMD-SHELL", "/usr/pgsql-12/bin/pg_isready -h localhost"]
      timeout: 20s
      interval: 30s
      retries: 5
    environment:
      CAMUNDA_PASSWORD: camunda
      CAMUNDA_DB: process-engine
      CAMUNDA_USER: camunda
      KEY_VAULT_USER: key_vault
      KEY_VAULT_DB: key_vault
      PG_MODE: primary
      PG_PRIMARY_USER: postgres
      PG_PRIMARY_PASSWORD: my_db_password
      PG_USER: postgres
      PG_PASSWORD: my_db_password
      PG_DATABASE: POSTGRESQL
      PG_ROOT_PASSWORD: my_db_password
      PG_PRIMARY_PORT: 5432
      MAX_CONNECTIONS: 1600
    volumes:
      - "/mnt/NASVolume/msa_db:/pgsqldata/pgsql"
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
 
  msa_api:
    image: openmsa/openmsa:msa2-api-2.8.5-5b300286e29aaf9c3f1621c1cd1acc13155a8037
    depends_on:
      - db
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8480"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
      update_config:
        parallelism: 1
      restart_policy:
        condition: on-failure
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/msa_api_logs:/opt/wildfly/logs/processLog"
    networks:
      default:
        aliases:
          - "msa-api"
  msa_ui:
    image: openmsa/openmsa:msa2-ui-2.8.5-28b4fa72ce3d16b1440002bcc0ee3784b535e839
    depends_on:
      - msa_api
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080"]
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
        constraints:
          - "node.role==manager"
    environment:
    - FEATURE_ADMIN=true
    - FEATURE_CONNECTION_STATUS=true
    - FEATURE_ALARMS=true
    - FEATURE_LICENCE=true
    - FEATURE_TOPOLOGY=true
    - FEATURE_MONITORING_PROFILES=true
    - FEATURE_PROFILE_AUDIT_LOGS=true
    - FEATURE_PERMISSION_PROFILES=true
    - FEATURE_AI_ML=true
    - FEATURE_MICROSERVICE_BULK_OPERATION=false
    - FEATURE_EDIT_VARIABLES_IN_MICROSERVICE_CONSOLE=true
    - FEATURE_WORKFLOW_OWNER=false
    - FEATURE_PERMISSION_PROFILE_LABELS=false

  msa_sms:
    image: openmsa/openmsa:msa2-sms-2.8.5-b79a6a992dec55d2714f629dfc4b1dc17c279e13
    depends_on:
      - db
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-sms status | grep -q 'service seems UP' || exit 1"] 
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_svn:/opt/svnroot"
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1

  msa_bud:
    image: openmsa/openmsa:msa2-bud-2.8.5-1c0b396972541832da0f8c1372c429bbdec87bf8
    depends_on:
      - db
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1

  msa_alarm:
    depends_on:
      - db
      - msa_api
    image: openmsa/openmsa:msa2-alarm-2.8.5-6debeb4a2fb8f61b2640f53cd88e6051d3a46121
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-alarm status | grep -q 'service seems UP' || exit 1"]
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    volumes:
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"

  msa_monitoring:
    image: openmsa/openmsa:msa2-monitoring-2.8.5-244d2706edda941858881ecd8f17089e3e1ea9b1
    healthcheck:
      test: ["CMD-SHELL", "/etc/init.d/ubi-poll status | grep -q 'service seems UP' || exit 1"]
    depends_on:
      - db
      - msa_es
      - msa_dev
    environment:
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    volumes:
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/rrd_repository:/opt/rrd"
      - "/mnt/NASVolume/msa_bulkfiles:/opt/sms/spool/parser"
      - "/mnt/NASVolume/msa_sms_logs:/opt/sms/logs"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1

  camunda:
    depends_on:
      - db
    image: openmsa/openmsa:msa2-camunda-2.8.5-23335a0df397d4bc3531366223cd5a239688ee0d
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    environment:
      DB_DRIVER: org.postgresql.Driver
      DB_URL: 'jdbc:postgresql://db:5432/process-engine'
      DB_USERNAME: camunda
      DB_PASSWORD: camunda
      DB_VALIDATE_ON_BORROW: 'true'
      WAIT_FOR: 'db:5432'
      WAIT_FOR_TIMEOUT: 60

  msa_es_create_certs:
    image: ubiqube/ubi-centos8:latest
    deploy:
      restart_policy:
        condition: none
    command: >
      bash -c '
        mkdir -p /usr/share/elasticsearch/config/certificates
        openssl req -x509 -nodes -days 365 -subj "/C=CA/ST=QC/O=UBiqube/CN=msa2.ubiqube.com" -newkey rsa:2048 -keyout /usr/share/elasticsearch/config/certificates/server.pem -out    /usr/share/elasticsearch/config/certificates/server.crt
        chown -R 1000:0 /usr/share/elasticsearch/config/certificates
      '
    user: "0"
    working_dir: /usr/share/elasticsearch
    volumes: 
      - "/mnt/NASVolume/msa_es_certs:/usr/share/elasticsearch/config/certificates"

  msa_es:
    image: openmsa/openmsa:msa2-es-2.8.5-f24b6d654d0307d5f7c55cd4a65ec8dbc747b1d1
    healthcheck:
      test: ["CMD-SHELL", "test -f /home/install/init-done && curl -s -XGET -H 'Authorization: Basic c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc='  'http://localhost:9200/_cluster/health?pretty' | grep -q 'status.*green' || exit 1"]
      timeout: 2s
      retries: 10
      interval: 10s
      start_period: 30s 
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    depends_on: 
      - msa_es_create_certs
    environment:
      - node.name=msa_es
      - discovery.seed_hosts=msa_es
      - cluster.initial_master_nodes=msa_es
      - cluster.name=es_cluster
      - "script.painless.regex.enabled=true"
#      - "bootstrap.memory_lock=true"
      - "ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc="
      - xpack.security.enabled=true
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.verification_mode=certificate
      - xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certificates/server.pem
      - xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certificates/server.crt
      - xpack.security.http.ssl.key=/usr/share/elasticsearch/config/certificates/server.pem
      - xpack.security.http.ssl.certificate=/usr/share/elasticsearch/config/certificates/server.crt
#      - ES_JAVA_OPTS=-Xms1024m -Xmx1024m
    ports:
      - "9200:9200"
    networks:
      default:
        aliases:
          - "msa_es"
    volumes:
      - "/mnt/NASVolume/msa_es_node_1:/usr/share/elasticsearch/data"
      - "/mnt/NASVolume/msa_es_certs:/usr/share/elasticsearch/config/certificates"


  msa_kibana:
    image: openmsa/openmsa:msa2-kibana-2.8.5-118f089ce6a140a7ef9991798c1029bace926539
    depends_on:
      - msa_es
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_URL=http://msa_es:9200
      - ELASTICSEARCH_HOSTS=http://msa_es:9200
      - ES_CREDENTIALS=c3VwZXJ1c2VyOnheWnl1R002fnU9K2ZZMkc=
    networks:
      default:
        aliases:
          - "msa-kibana"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
          
  msa_ai_ml:
    image: openmsa/openmsa:msa2-ai-ml-2.8.5-63c7fab8c111b6cc85da049f45ebc6175a9b269a
    healthcheck:
      test: ["CMD-SHELL", "python /msa_proj/health_check.py"]
    ports:
      - "8000:8000"
    volumes:
      - "/mnt/NASVolume/msa_ai_ml_db:/msa_proj/database"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    networks:
      default:
        aliases:
          - "msa-ai-ml"

  msa_cerebro:
    image: openmsa/openmsa:msa2-cerebro-2.8.5-914750e000db1343d9972bfa6652da1efe4aa32f
    environment:
      AUTH_TYPE: basic
      BASIC_AUTH_USER: cerebro
      BASIC_AUTH_PWD: "N@X{M4tfw'5%)+35"
    entrypoint:
      - /opt/cerebro/bin/cerebro
      - -Dhosts.0.host=http://msa_es:9200
    depends_on:
      - msa_es
    ports:
      - "9000:9000"
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1

  msa_dev:
    image: openmsa/openmsa:msa2-linuxdev-2.8.5-1e2e15527e8b13a3b0f0f76cb9ed21303b93c854
    depends_on:
      - msa_es
    deploy:
      replicas: 1
      placement:
        max_replicas_per_node: 1
    volumes:
      - "/mnt/NASVolume/msa_entities:/opt/fmc_entities"
      - "/mnt/NASVolume/msa_repository:/opt/fmc_repository"
      - "/mnt/NASVolume/msa_dev:/opt/devops/"
      - "/mnt/NASVolume/msa_svn:/opt/svnroot"

networks:
  default:
    driver: overlay
    driver_opts:
      encrypted: "true"









